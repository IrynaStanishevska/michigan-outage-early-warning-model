{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import json\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, log_loss, brier_score_loss,\n",
        "    precision_score, recall_score, f1_score,\n",
        "    mean_squared_error, mean_absolute_error, r2_score\n",
        ")\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "K1DGi1vEa7sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m10e7OogZ40l"
      },
      "outputs": [],
      "source": [
        "def set_random_seeds(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
        "    os.environ['PYTHONHASHSEED'] = \"42\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_random_seeds(42)"
      ],
      "metadata": {
        "id": "tHl7f1-wbCEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# features excluded from the final feature set based on prior feature selection\n",
        "# + technical columns\n",
        "excluded_features = [ 'x','sq_flag',\n",
        "    'drct_v_lag_6h','drct_v_lag_12h','drct_v_lag_24h','drct_v_lag_48h',\n",
        "    'drct_u_lag_6h','drct_u_lag_24h','drct_u_lag_48h',\n",
        "    'tmpf_lag_12h','tmpf_lag_24h','tmpf_lag_48h',\n",
        "    'hr_flag_rolling_sum_6h','hr_flag_rolling_sum_12h','hr_flag_rolling_sum_24h','hr_flag_rolling_sum_48h',\n",
        "    'sq_flag_rolling_sum_6h','sq_flag_rolling_sum_12h','sq_flag_rolling_sum_24h','sq_flag_rolling_sum_48h',\n",
        "    'relh_grad_rolling_max_6h','relh_grad_rolling_max_12h','relh_grad_rolling_max_24h','relh_grad_rolling_max_48h',\n",
        "    'ts_flag_rolling_sum_6h','ts_flag_rolling_sum_12h','ts_flag_rolling_sum_24h','ts_flag_rolling_sum_48h',\n",
        "    'mslp_rolling_mean_6h','mslp_rolling_mean_12h','mslp_rolling_mean_24h','mslp_rolling_mean_48h',\n",
        "    'gust_rolling_max_12h','gust_rolling_max_24h','gust_rolling_max_48h',\n",
        "    'alti_rolling_mean_6h','alti_rolling_mean_12h','alti_rolling_mean_24h','alti_rolling_mean_48h',\n",
        "    'sknt_rolling_max_6h','sknt_rolling_max_12h','sknt_rolling_max_24h','sknt_rolling_max_48h',\n",
        "    'relh_rolling_mean_6h','relh_rolling_mean_12h','relh_rolling_mean_24h','relh_rolling_mean_48h',\n",
        "    'p0li_rolling_sum_6h','p0li_rolling_sum_12h','p0li_rolling_sum_24h','p0li_rolling_sum_48h',\n",
        "    'time_interval','anomaly_threshold', 'year',\n",
        "    'IDW_ts_flag_rolling_sum_12h']\n",
        "\n",
        "df = df.drop(columns=excluded_features, errors='ignore')"
      ],
      "metadata": {
        "id": "y7_JyjJB7cgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91XP5wf-iJnU"
      },
      "source": [
        "Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train and test split\n",
        "df = df.sort_values('run_start_time').reset_index(drop=True)\n",
        "\n",
        "df_train = df[df.run_start_time.dt.year == 2021].copy()\n",
        "df_test  = df[df.run_start_time.dt.year == 2022].copy()\n",
        "\n",
        "print(\"Train shape (before):\", df_train.shape)\n",
        "print(df_train['target_anomaly_48h'].value_counts())\n",
        "\n",
        "# prepare 48h windows\n",
        "df_train['time_interval'] = df_train['run_start_time'].dt.floor('48H')\n",
        "\n",
        "kept_intervals = []\n",
        "\n",
        "# iteration on counties\n",
        "for county, df_county in df_train.groupby('fips_code'):\n",
        "\n",
        "    for interval, interval_data in df_county.groupby('time_interval'):\n",
        "        interval_data = interval_data.copy()\n",
        "\n",
        "        y = interval_data['target_anomaly_48h'].values\n",
        "        num_pos, num_neg = y.sum(), len(y) - y.sum()\n",
        "\n",
        "        if (num_pos >= 3) and (num_neg >= 1):     # append windows if the number of Class 1 >= 3 and Class 0 >= 1 to avoid uninformative windows\n",
        "            kept_intervals.append(interval_data)\n",
        "\n",
        "# concatenate resulted windows\n",
        "df_train_us = (                       # us = undersampled\n",
        "    pd.concat(kept_intervals, ignore_index=True)\n",
        "      .sort_values(['run_start_time', 'fips_code'])\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "print(\"\\nTrain shape (after):\", df_train_us.shape)\n",
        "print(df_train_us['target_anomaly_48h'].value_counts())\n",
        "\n",
        "print(\"\\nTest shape :\", df_test.shape)\n",
        "print(df_test['target_anomaly_48h'].value_counts())\n",
        "\n",
        "print('Train period:', df_train_us.run_start_time.min(), '–', df_train_us.run_start_time.max())\n",
        "print('Test period :', df_test.run_start_time.min(),  '–', df_test.run_start_time.max())"
      ],
      "metadata": {
        "id": "y57qJnKkiJnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XsGBbNPiJnY"
      },
      "source": [
        "1. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTtmvfqhiJnY"
      },
      "outputs": [],
      "source": [
        "# Stage-1 Cross Fold Validation\n",
        "\n",
        "features_to_drop = [\n",
        "    'run_start_time', 'target_anomaly_48h', 'target_flag', 'sum_48','fips_code', # technical columns\n",
        "    'state_sum_48h', 'target_flag_24','run_start_time_plus_48','sum','anomaly_flag',\n",
        "\n",
        "    'dwpf','tmpf','relh','alti','mslp','gust','p0li','sknt','drct_u','drct_v','relh_grad','ts_flag','hr_flag', # LSTM features\n",
        "    'dwpf_lag_6h','dwpf_lag_24h','dwpf_lag_48h','gust_rolling_max_6h','idw_rolling_max_24h','IDW_dwpf','IDW_alti',\n",
        "    'IDW_drct_v','IDW_drct_u','IDW_drct_v_lag_6h','IDW_p0li_rolling_sum_24h','IDW_gust_rolling_max_24h',\n",
        "    'IDW_sknt_rolling_max_48h','IDW_relh_rolling_mean_48h',\n",
        "    'day_of_week_num','population_density','county_encoded','y'\n",
        "\n",
        "]\n",
        "\n",
        "# settings\n",
        "threshold   = 0.50\n",
        "TARGET_COL  = 'target_anomaly_48h'\n",
        "N_SPLITS    = 3\n",
        "C_VAL       = 0.001\n",
        "CLASS_WT    = {0: 1, 1: 5}\n",
        "\n",
        "X_us = df_train_us.drop(columns=features_to_drop, errors='ignore').copy()\n",
        "y_us = df_train_us[TARGET_COL].copy()\n",
        "\n",
        "# keep numeric columns only\n",
        "non_num = X_us.select_dtypes(exclude=['int64', 'float64']).columns\n",
        "if len(non_num):\n",
        "    X_us.drop(columns=non_num, inplace=True)\n",
        "\n",
        "# replace infinite values with NaN for imputer\n",
        "X_us.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "num_cols = X_us.columns          # final feature set\n",
        "\n",
        "# time based split\n",
        "times     = np.sort(df_train_us['run_start_time'].unique())\n",
        "fold_len  = len(times) // (N_SPLITS + 1)\n",
        "folds     = [(times[: i * fold_len],\n",
        "              times[i * fold_len : (i + 1) * fold_len])\n",
        "             for i in range(1, N_SPLITS + 1)]\n",
        "\n",
        "\n",
        "metrics = {'train': [], 'val': []}\n",
        "coefs   = []\n",
        "\n",
        "# scaling\n",
        "imp    = SimpleImputer(strategy='median') # median imputer\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "for k, (t_train, t_val) in enumerate(folds, 1):\n",
        "    idx_tr = df_train_us['run_start_time'].isin(t_train)\n",
        "    idx_va = df_train_us['run_start_time'].isin(t_val)\n",
        "\n",
        "    X_tr = X_us.loc[idx_tr, num_cols].copy()\n",
        "    y_tr = y_us[idx_tr].copy()\n",
        "    X_va = X_us.loc[idx_va, num_cols].copy()\n",
        "    y_va = y_us[idx_va].copy()\n",
        "\n",
        "    # imputer and scaling\n",
        "    X_tr[num_cols] = imp.fit_transform(X_tr[num_cols])\n",
        "    X_va[num_cols] = imp.transform(X_va[num_cols])\n",
        "    X_tr[num_cols] = scaler.fit_transform(X_tr[num_cols])\n",
        "    X_va[num_cols] = scaler.transform(X_va[num_cols])\n",
        "\n",
        "    # model\n",
        "    lg = LogisticRegression(C=C_VAL, class_weight=CLASS_WT,\n",
        "                            penalty='l2', solver='lbfgs',\n",
        "                            max_iter=1000, random_state=42)\n",
        "    lg.fit(X_tr, y_tr)\n",
        "    coefs.append(lg.coef_[0])\n",
        "\n",
        "    # metrics\n",
        "    for tag, X_, y_ in [('train', X_tr, y_tr), ('val', X_va, y_va)]:\n",
        "        p = lg.predict_proba(X_)[:, 1]\n",
        "        m = {\n",
        "            'AUC'      : roc_auc_score(y_, p),\n",
        "            'LogLoss'  : log_loss(y_, p),\n",
        "            'Brier'    : brier_score_loss(y_, p),\n",
        "            'Precision': precision_score(y_, p >= threshold, zero_division=0),\n",
        "            'Recall'   : recall_score(   y_, p >= threshold, zero_division=0),\n",
        "            'F1'       : f1_score(       y_, p >= threshold, zero_division=0)\n",
        "        }\n",
        "        metrics[tag].append(m)\n",
        "\n",
        "    tr = metrics['train'][-1]; va = metrics['val'][-1]\n",
        "    print(f\"\\nFold {k}\")\n",
        "    print(\"  TRAIN:\", \", \".join(f\"{k}:{v:.3f}\" for k,v in tr.items()))\n",
        "    print(\"  VAL  :\", \", \".join(f\"{k}:{v:.3f}\" for k,v in va.items()))\n",
        "\n",
        "# average on folds\n",
        "avg = lambda lst: {m: np.mean([d[m] for d in lst]) for m in lst[0]}\n",
        "\n",
        "print(\"\\n=== Average metrics over folds ===\")\n",
        "print(\"TRAIN:\", \", \".join(f\"{k}:{v:.3f}\" for k,v in avg(metrics['train']).items()))\n",
        "print(\"VAL  :\", \", \".join(f\"{k}:{v:.3f}\" for k,v in avg(metrics['val']).items()))\n",
        "\n",
        "# feature importance\n",
        "avg_coef = np.mean(coefs, axis=0)\n",
        "imp_df = (pd.DataFrame({'feature': num_cols,\n",
        "                        'coef': avg_coef,\n",
        "                        'abs': np.abs(avg_coef)})\n",
        "            .sort_values('abs', ascending=False))\n",
        "\n",
        "print(\"\\nTop-15 features (|coef|):\")\n",
        "print(imp_df.head(15))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stage-1: Final train on the entire df_train_us with the same imputer and a new scaler_full\n",
        "\n",
        "# train imputer on full df_train_us\n",
        "imp_full = SimpleImputer(strategy='median')\n",
        "imp_full.fit(X_us[num_cols])\n",
        "\n",
        "X_imp_full = imp_full.transform(X_us[num_cols])\n",
        "\n",
        "# train scaler\n",
        "scaler_full = MinMaxScaler()\n",
        "scaler_full.fit(X_imp_full)\n",
        "\n",
        "X_scaled_full = scaler_full.transform(X_imp_full)\n",
        "\n",
        "# final model\n",
        "final_model = LogisticRegression(\n",
        "        C=0.001, penalty='l2', class_weight={0: 1, 1: 5},\n",
        "        solver='lbfgs', max_iter=1000, random_state=42\n",
        ")\n",
        "final_model.fit(X_scaled_full, y_us)\n",
        "\n",
        "print(\"\\n✔  Stage-1 final model trained on **all** df_train_us\")\n",
        "\n",
        "# metrics\n",
        "proba_full = final_model.predict_proba(X_scaled_full)[:, 1]\n",
        "pred_full  = (proba_full >= threshold).astype(int)\n",
        "\n",
        "print(\"\\n===  Metrics on FULL df_train_us  ===\")\n",
        "print(f\"AUC      : {roc_auc_score(y_us, proba_full):.3f}\")\n",
        "print(f\"LogLoss  : {log_loss(y_us, proba_full):.3f}\")\n",
        "print(f\"Brier    : {brier_score_loss(y_us, proba_full):.3f}\")\n",
        "print(f\"Prec / Rec / F1 = \"\n",
        "      f\"{precision_score(y_us, pred_full):.3f} / \"\n",
        "      f\"{recall_score(  y_us, pred_full):.3f} / \"\n",
        "      f\"{f1_score(      y_us, pred_full):.3f}\")"
      ],
      "metadata": {
        "id": "Vhrmin1VM3_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgndcKY3iJnZ"
      },
      "outputs": [],
      "source": [
        "# Stage-1: train on the real train set\n",
        "threshold   = 0.7 # updated thershold for real imbalanced training set\n",
        "TARGET_COL  = 'target_anomaly_48h'\n",
        "\n",
        "\n",
        "df_train_real = df_train.copy()\n",
        "\n",
        "X_train_real = (\n",
        "    df_train_real\n",
        "      .drop(columns=features_to_drop, errors='ignore')\n",
        "      .copy()\n",
        ")\n",
        "\n",
        "# train global imputer and scaler\n",
        "imp = SimpleImputer(strategy='median')\n",
        "imp.fit(X_us[num_cols])\n",
        "\n",
        "X_imp = pd.DataFrame(\n",
        "    imp.transform(X_us[num_cols]),\n",
        "    columns=num_cols,\n",
        "    index=X_us.index\n",
        ")\n",
        "\n",
        "scaler_full = MinMaxScaler()\n",
        "scaler_full.fit(X_imp)\n",
        "\n",
        "cols_imp    = list(imp.feature_names_in_)   # features after imputer\n",
        "cols_scaler = cols_imp[:]                   # the same order for MinMax\n",
        "\n",
        "\n",
        "# reindex infinitive values and NaN for imputer\n",
        "X_train_real = X_train_real.reindex(columns=cols_imp)\n",
        "X_train_real.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_train_real.loc[:, :] = imp.transform(X_train_real)\n",
        "\n",
        "\n",
        "X_train_scaled = pd.DataFrame(\n",
        "    X_train_real[cols_scaler].values,\n",
        "    columns=cols_scaler,\n",
        "    index=X_train_real.index\n",
        ")\n",
        "X_train_scaled.loc[:, :] = scaler_full.transform(X_train_scaled)\n",
        "\n",
        "# prediction and metrics\n",
        "y_train_proba = final_model.predict_proba(X_train_scaled)[:, 1]\n",
        "df_train_real['pred_class_1stage'] = (y_train_proba >= threshold).astype(int)\n",
        "\n",
        "y_true = df_train_real[TARGET_COL].values\n",
        "y_pred = df_train_real['pred_class_1stage'].values\n",
        "\n",
        "print(\"\\n=== Metrics on REAL TRAIN (summer-2021) ===\")\n",
        "print(f\"AUC     : {roc_auc_score(y_true, y_train_proba):.3f}\")\n",
        "print(f\"LogLoss : {log_loss(y_true, y_train_proba):.3f}\")\n",
        "print(f\"Brier   : {brier_score_loss(y_true, y_train_proba):.3f}\")\n",
        "print(f\"Precision / Recall / F1 = \"\n",
        "      f\"{precision_score(y_true, y_pred, zero_division=0):.3f} / \"\n",
        "      f\"{recall_score(   y_true, y_pred, zero_division=0):.3f} / \"\n",
        "      f\"{f1_score(       y_true, y_pred, zero_division=0):.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBUxeuPsiJnZ"
      },
      "outputs": [],
      "source": [
        "# Stage-1: train on Test set\n",
        "threshold  = 0.7          # the same thershold as used on full train\n",
        "TARGET_COL = 'target_anomaly_48h'\n",
        "\n",
        "df_test_real = df_test.copy()\n",
        "\n",
        "# feature set\n",
        "X_test_real = (\n",
        "    df_test_real\n",
        "      .drop(columns=features_to_drop, errors='ignore')\n",
        "      .copy()\n",
        ")\n",
        "\n",
        "\n",
        "# the same column list\n",
        "cols_imp    = list(imp.feature_names_in_)             # for SimpleImputer\n",
        "cols_scaler = list(scaler_full.feature_names_in_)     # for MinMaxScaler\n",
        "\n",
        "# imputed set\n",
        "X_test_real = X_test_real.reindex(columns=cols_imp)\n",
        "\n",
        "# use NaN for infinitive value before imputation\n",
        "X_test_real.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test_real.loc[:, :] = imp.transform(X_test_real)\n",
        "\n",
        "\n",
        "# keep scaler columns\n",
        "X_test_scaled = pd.DataFrame(\n",
        "    X_test_real[cols_scaler].values,\n",
        "    columns=cols_scaler,\n",
        "    index=X_test_real.index\n",
        ")\n",
        "X_test_scaled.loc[:, :] = scaler_full.transform(X_test_scaled)\n",
        "\n",
        "# probability of class 1\n",
        "y_test_proba = final_model.predict_proba(X_test_scaled)[:, 1]\n",
        "df_test_real['pred_class_1stage'] = (y_test_proba >= threshold).astype(int)\n",
        "# df_test_real['pred_proba_1stage'] = y_test_proba   # if needed\n",
        "\n",
        "# metrics\n",
        "from sklearn.metrics import (roc_auc_score, log_loss, brier_score_loss,\n",
        "                             precision_score, recall_score, f1_score)\n",
        "\n",
        "y_true = df_test_real[TARGET_COL].values\n",
        "y_pred = df_test_real['pred_class_1stage'].values\n",
        "\n",
        "print(\"\\n=== Metrics on TEST-2022 ===\")\n",
        "print(f\"AUC     : {roc_auc_score(y_true, y_test_proba):.3f}\")\n",
        "print(f\"LogLoss : {log_loss(y_true, y_test_proba):.3f}\")\n",
        "print(f\"Brier   : {brier_score_loss(y_true, y_test_proba):.3f}\")\n",
        "print(f\"P / R / F1 = \"\n",
        "      f\"{precision_score(y_true, y_pred, zero_division=0):.3f} / \"\n",
        "      f\"{recall_score(   y_true, y_pred, zero_division=0):.3f} / \"\n",
        "      f\"{f1_score(       y_true, y_pred, zero_division=0):.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TARGET_COL = 'target_anomaly_48h'\n",
        "PRED_COL   = 'pred_class_1stage'      # classification label\n",
        "\n",
        "def audit_stage1(df: pd.DataFrame, tag: str = \"TRAIN\"):\n",
        "    \"\"\" Statistics after Stage-1.\"\"\"\"\"\n",
        "\n",
        "    # Confusion matrix\n",
        "    tn, fp, fn, tp = confusion_matrix(df[TARGET_COL], df[PRED_COL]).ravel()\n",
        "    print(f\"\\n=== {tag} — confusion matrix ===\")\n",
        "    print(f\"TP = {tp:>6}   FP = {fp:>6}\")\n",
        "    print(f\"FN = {fn:>6}   TN = {tn:>6}\")\n",
        "\n",
        "    # Class balance before Stage-1\n",
        "    share_pos_raw = df[TARGET_COL].mean()\n",
        "    print(f\"\\nRaw class balance   :  pos = {share_pos_raw:6.2%}   \"\n",
        "          f\"neg = {1-share_pos_raw:6.2%}\")\n",
        "\n",
        "    # Class balance after Stage-1 (Stage-2 sample set)\n",
        "    df_stage2 = df.query(f\"{PRED_COL} == 1\")\n",
        "    share_pos_stage2 = df_stage2[TARGET_COL].mean() if not df_stage2.empty else 0\n",
        "    print(f\"After Stage-1 filter:  pos = {share_pos_stage2:6.2%}   \"\n",
        "          f\"neg = {1-share_pos_stage2:6.2%}\")\n",
        "    print(f\"Stage-2 sample size :  {len(df_stage2):,} rows \"\n",
        "          f\"(из {len(df):,},  {len(df_stage2)/len(df):.2%})\")\n",
        "\n",
        "\n",
        "audit_stage1(df_train_real, \"TRAIN-2021\")\n",
        "audit_stage1(df_test_real , \"TEST-2022\")"
      ],
      "metadata": {
        "id": "CDQD9SvPZF_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoGRp17NiJnZ"
      },
      "source": [
        "2. LSTM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stage-2: LSTM Regressor\n",
        "# uses the same dataset as in Stage-1 but training only on samples where Stage-1 predicted class == 1\n",
        "\n",
        "# feature names as seen by SimpleImputer and MinMaxScaler during fit\n",
        "cols_imp    = list(imp.feature_names_in_) # used for imputer\n",
        "cols_scaler = list(scaler_full.feature_names_in_) # used for scaling\n",
        "\n",
        "# kep only Stage-1 sample == class 1\n",
        "df_reg_train_stage2 = df_train_real.query(\"pred_class_1stage == 1\").copy()\n",
        "df_reg_test_stage2  = df_test_real .query(\"pred_class_1stage == 1\").copy()\n",
        "\n",
        "for _df in (df_reg_train_stage2, df_reg_test_stage2):\n",
        "\n",
        "    # drop unused features and reindex to match imputer inputation\n",
        "    _df_feats = (_df\n",
        "                 .drop(columns=features_to_drop, errors='ignore')\n",
        "                 .reindex(columns=cols_imp))\n",
        "\n",
        "    # replace infinitive values with NaN and apply imputation\n",
        "    _df_feats.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    _df_feats.loc[:, :] = imp.transform(_df_feats)\n",
        "\n",
        "    # applu scaling using Stage-1 scaler\n",
        "    _df_scaled = pd.DataFrame(\n",
        "        _df_feats[cols_scaler].values,\n",
        "        columns=cols_scaler,\n",
        "        index=_df_feats.index\n",
        "    )\n",
        "    _df_scaled.loc[:, :] = scaler_full.transform(_df_scaled)\n",
        "\n",
        "    # write scaled features back to the dataframe\n",
        "    _df.loc[:, cols_scaler] = _df_scaled\n",
        "\n",
        "    # Add log transformed regression target\n",
        "    _df['log_sum_48'] = np.log1p(_df['sum_48'])\n",
        "\n",
        "print(\"Reg train stage2:\", df_reg_train_stage2.shape)\n",
        "print(\"Reg  test stage2:\", df_reg_test_stage2.shape)"
      ],
      "metadata": {
        "id": "F2K3DsJCiJnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCJYlBDgiJna"
      },
      "outputs": [],
      "source": [
        "# Stage-2: Cross Validation\n",
        "\n",
        "# X and Y\n",
        "df_reg_2021 = df_reg_train_stage2.copy()\n",
        "\n",
        "# columns to drop\n",
        "cols_to_drop = [\n",
        "    'pred_class_1stage', 'pred_class_1stage_proba',                               # technical columns\n",
        "    'run_start_time', 'target_anomaly_48h', 'target_flag', 'sum_48','fips_code',\n",
        "    'state_sum_48h', 'target_flag_24','run_start_time_plus_48','sum','anomaly_flag',\n",
        "    'log_sum_48',\n",
        "\n",
        "    'rolling_max_12h','rolling_mean_12h','tmpf_lag_6h','drct_u_lag_12h' # Stage-1 features\n",
        "]\n",
        "\n",
        "X_2021 = df_reg_2021.drop(columns=cols_to_drop, errors='ignore')\n",
        "y_2021 = df_reg_2021['log_sum_48'].copy()\n",
        "\n",
        "# drop non numeric columns\n",
        "non_numeric_cols = X_2021.select_dtypes(exclude=['int64','float64']).columns\n",
        "if len(non_numeric_cols) > 0:\n",
        "    print(\"Dropping non-numeric columns from X_2021:\", non_numeric_cols.tolist())\n",
        "    X_2021.drop(columns=non_numeric_cols, inplace=True, errors='ignore')\n",
        "\n",
        "print(\"X_2021 shape:\", X_2021.shape, \"y_2021 shape:\", y_2021.shape)\n",
        "\n",
        "# Timeseries split wirh 3 folds\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "fold_metrics = []\n",
        "\n",
        "numeric_cols = X_2021.columns\n",
        "\n",
        "# Iteration by folds\n",
        "for fold_idx, (train_index, val_index) in enumerate(tscv.split(X_2021), start=1):\n",
        "    # split folds\n",
        "    X_train_fold = X_2021.iloc[train_index].copy()\n",
        "    y_train_fold = y_2021.iloc[train_index].copy()\n",
        "\n",
        "    X_val_fold   = X_2021.iloc[val_index].copy()\n",
        "    y_val_fold   = y_2021.iloc[val_index].copy()\n",
        "\n",
        "    # infinitive to NaN\n",
        "    for _df in (X_train_fold, X_val_fold):\n",
        "        _df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "    # imputer\n",
        "    imp_fold = SimpleImputer(strategy='median')\n",
        "    X_train_fold[numeric_cols] = imp_fold.fit_transform(X_train_fold[numeric_cols])\n",
        "    X_val_fold[numeric_cols]   = imp_fold.transform(   X_val_fold[numeric_cols])\n",
        "\n",
        "    scaler_fold = MinMaxScaler()\n",
        "    X_train_fold[numeric_cols] = scaler_fold.fit_transform(X_train_fold[numeric_cols])\n",
        "    X_val_fold[numeric_cols]   = scaler_fold.transform(   X_val_fold[numeric_cols])\n",
        "\n",
        "\n",
        "    # Приводим к (samples, 1, features)\n",
        "    X_train_3d = X_train_fold.values.reshape(\n",
        "        (X_train_fold.shape[0], 1, X_train_fold.shape[1])\n",
        "    )\n",
        "    X_val_3d   = X_val_fold.values.reshape(\n",
        "        (X_val_fold.shape[0], 1, X_val_fold.shape[1])\n",
        "    )\n",
        "\n",
        "    # model\n",
        "    n_features = X_train_3d.shape[2]\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.LSTM(16, input_shape=(1, n_features)))\n",
        "    model.add(layers.Dense(1, activation='relu'))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "\n",
        "    early_stopping = EarlyStopping(\n",
        "       monitor='val_loss', patience=2, restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    # fit\n",
        "    model.fit(\n",
        "        X_train_3d, y_train_fold,\n",
        "        epochs=30, batch_size=32,\n",
        "        validation_data=(X_val_3d, y_val_fold),\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # predict\n",
        "    y_val_pred = model.predict(X_val_3d).ravel()\n",
        "\n",
        "    # Log metrics\n",
        "    mse_val_log = mean_squared_error(y_val_fold, y_val_pred)\n",
        "    rmse_val_log = np.sqrt(mse_val_log)\n",
        "    mae_val_log = mean_absolute_error(y_val_fold, y_val_pred)\n",
        "    r2_val_log = r2_score(y_val_fold, y_val_pred)\n",
        "\n",
        "    # Metrics in original scale\n",
        "    y_val_true_orig = np.expm1(y_val_fold)\n",
        "    y_val_pred_orig = np.expm1(y_val_pred)\n",
        "    mse_val_orig = mean_squared_error(y_val_true_orig, y_val_pred_orig)\n",
        "    rmse_val_orig = np.sqrt(mse_val_orig)\n",
        "    mae_val_orig = mean_absolute_error(y_val_true_orig, y_val_pred_orig)\n",
        "    r2_val_orig = r2_score(y_val_true_orig, y_val_pred_orig)\n",
        "\n",
        "    # all metrics in one dict\n",
        "    fold_metrics.append({\n",
        "       'mse_log':  mse_val_log,\n",
        "       'rmse_log': rmse_val_log,\n",
        "       'mae_log':  mae_val_log,\n",
        "       'r2_log':   r2_val_log,\n",
        "       'mse_orig':  mse_val_orig,\n",
        "       'rmse_orig': rmse_val_orig,\n",
        "       'mae_orig':  mae_val_orig,\n",
        "       'r2_orig':   r2_val_orig\n",
        "    })\n",
        "\n",
        "    print(f\"\\n[Fold {fold_idx} / {tscv.n_splits}] LOG-scale => \"\n",
        "          f\"MSE={mse_val_log:.4f}, RMSE={rmse_val_log:.4f}, MAE={mae_val_log:.4f}, R^2={r2_val_log:.4f}\")\n",
        "    print(f\"                       Orig-scale => \"\n",
        "          f\"MSE={mse_val_orig:.2f}, RMSE={rmse_val_orig:.2f}, MAE={mae_val_orig:.2f}, R^2={r2_val_orig:.4f}\")\n",
        "\n",
        "# averaged metrics by folds\n",
        "def mean_of_metric(fold_metrics, key):\n",
        "    return np.mean([fm[key] for fm in fold_metrics])\n",
        "\n",
        "avg_mse_log  = mean_of_metric(fold_metrics, 'mse_log')\n",
        "avg_rmse_log = mean_of_metric(fold_metrics, 'rmse_log')\n",
        "avg_mae_log  = mean_of_metric(fold_metrics, 'mae_log')\n",
        "avg_r2_log   = mean_of_metric(fold_metrics, 'r2_log')\n",
        "\n",
        "print(\"\\n=== Cross-Validation (log-scale) ===\")\n",
        "print(f\"MSE:  {avg_mse_log:.4f}\")\n",
        "print(f\"RMSE: {avg_rmse_log:.4f}\")\n",
        "print(f\"MAE:  {avg_mae_log:.4f}\")\n",
        "print(f\"R^2:  {avg_r2_log:.4f}\")\n",
        "\n",
        "avg_mse_orig  = mean_of_metric(fold_metrics, 'mse_orig')\n",
        "avg_rmse_orig = mean_of_metric(fold_metrics, 'rmse_orig')\n",
        "avg_mae_orig  = mean_of_metric(fold_metrics, 'mae_orig')\n",
        "avg_r2_orig   = mean_of_metric(fold_metrics, 'r2_orig')\n",
        "\n",
        "print(\"\\n=== Cross-Validation (original scale) ===\")\n",
        "print(f\"MSE:  {avg_mse_orig:.2f}\")\n",
        "print(f\"RMSE: {avg_rmse_orig:.2f}\")\n",
        "print(f\"MAE:  {avg_mae_orig:.2f}\")\n",
        "print(f\"R^2:  {avg_r2_orig:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxI4k4T9iJna"
      },
      "outputs": [],
      "source": [
        "# Stage-2 Train (2021)\n",
        "\n",
        "print(\"Initial train shapes :\", X_2021.shape, y_2021.shape)\n",
        "\n",
        "# list of numeric columns\n",
        "num_cols = X_2021.columns\n",
        "\n",
        "# median-impute\n",
        "X_2021.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "imp_final = SimpleImputer(strategy='median')\n",
        "X_2021[num_cols] = imp_final.fit_transform(X_2021[num_cols])\n",
        "\n",
        "# Min–Max scailing\n",
        "scaler_final = MinMaxScaler()\n",
        "X_2021_scaled = scaler_final.fit_transform(X_2021[num_cols])\n",
        "\n",
        "# reshape (samples, 1, n_features)\n",
        "X_2021_3d = X_2021_scaled.reshape(\n",
        "    (X_2021_scaled.shape[0], 1, X_2021_scaled.shape[1])\n",
        ")\n",
        "print(\"LSTM input shapes   :\", X_2021_3d.shape, y_2021.shape)\n",
        "\n",
        "# LSTM Model (one-step)\n",
        "n_features = X_2021_3d.shape[2]\n",
        "model_final = keras.Sequential([\n",
        "    layers.LSTM(16, input_shape=(1, n_features)),\n",
        "    layers.Dense(1, activation='relu')\n",
        "])\n",
        "model_final.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='loss', patience=2, restore_best_weights=True\n",
        ")\n",
        "\n",
        "model_final.fit(\n",
        "    X_2021_3d, y_2021,\n",
        "    epochs=30, batch_size=32,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "# Metrics on Training set (log-scale)\n",
        "y_pred_log = model_final.predict(X_2021_3d, verbose=0).ravel()\n",
        "\n",
        "mse_log  = mean_squared_error(y_2021, y_pred_log)\n",
        "rmse_log = np.sqrt(mse_log)\n",
        "mae_log  = mean_absolute_error(y_2021, y_pred_log)\n",
        "r2_log   = r2_score(y_2021, y_pred_log)\n",
        "\n",
        "print(\"\\nFinal model TRAIN (log-scale)\")\n",
        "print(f\"MSE={mse_log:.4f}  RMSE={rmse_log:.4f}  \"\n",
        "      f\"MAE={mae_log:.4f}  R²={r2_log:.4f}\")\n",
        "\n",
        "# Metrics on Training set (original scale)\n",
        "\n",
        "y_true_orig = np.expm1(y_2021)\n",
        "y_pred_orig = np.expm1(y_pred_log)\n",
        "\n",
        "mse_orig  = mean_squared_error(y_true_orig, y_pred_orig)\n",
        "rmse_orig = np.sqrt(mse_orig)\n",
        "mae_orig  = mean_absolute_error(y_true_orig, y_pred_orig)\n",
        "r2_orig   = r2_score(y_true_orig, y_pred_orig)\n",
        "\n",
        "print(\"\\nFinal model TRAIN (original scale) \")\n",
        "print(f\"MSE={mse_orig:,.2f}  RMSE={rmse_orig:,.2f}  \"\n",
        "      f\"MAE={mae_orig:,.2f}  R²={r2_orig:.4f}\")\n",
        "\n",
        "# save imputer for test set\n",
        "joblib.dump(imp_final,    \"imp_stage2.joblib\")\n",
        "joblib.dump(scaler_final, \"scaler_stage2.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tdWgDJ9iJna"
      },
      "outputs": [],
      "source": [
        "# Stage-2 Test (2022)\n",
        "\n",
        "df_reg_test_2022 = df_reg_test_stage2.copy()\n",
        "\n",
        "# numeric columns\n",
        "X_test = (\n",
        "    df_reg_test_2022\n",
        "      .drop(columns=cols_to_drop, errors='ignore')\n",
        "      .reindex(columns=num_cols)          # fixing the order\n",
        ")\n",
        "y_test_log = df_reg_test_2022['log_sum_48'].copy()\n",
        "\n",
        "# infinitive to NaN; SimpleImputer; scaler_final\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test[num_cols] = imp_final.transform(X_test[num_cols])     # using the same imputer\n",
        "X_test_scaled    = scaler_final.transform(X_test[num_cols])  # only .transform\n",
        "\n",
        "# reshape for LSTM\n",
        "X_test_3d = X_test_scaled.reshape(\n",
        "    (X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
        ")\n",
        "\n",
        "# predict\n",
        "y_test_pred_log = model_final.predict(X_test_3d).ravel()\n",
        "\n",
        "# metrics (log-scale)\n",
        "mse_log  = mean_squared_error(y_test_log, y_test_pred_log)\n",
        "rmse_log = np.sqrt(mse_log)\n",
        "mae_log  = mean_absolute_error(y_test_log, y_test_pred_log)\n",
        "r2_log   = r2_score(y_test_log, y_test_pred_log)\n",
        "\n",
        "print(\"\\nFinal model on TEST-2022 (log-scale)\")\n",
        "print(f\"MSE={mse_log:.4f}, RMSE={rmse_log:.4f}, MAE={mae_log:.4f}, R²={r2_log:.4f}\")\n",
        "\n",
        "# metrics (original scale)\n",
        "y_true_orig = np.expm1(y_test_log)\n",
        "y_pred_orig = np.expm1(y_test_pred_log)\n",
        "\n",
        "mse_orig  = mean_squared_error(y_true_orig, y_pred_orig)\n",
        "rmse_orig = np.sqrt(mse_orig)\n",
        "mae_orig  = mean_absolute_error(y_true_orig, y_pred_orig)\n",
        "r2_orig   = r2_score(y_true_orig, y_pred_orig)\n",
        "\n",
        "print(\"\\nFinal model on TEST-2022 (original scale)\")\n",
        "print(f\"MSE={mse_orig:.2f}, RMSE={rmse_orig:.2f}, MAE={mae_orig:.2f}, R²={r2_orig:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4JesAkmtOMKC",
        "rsotk1R3Oi4I",
        "R-ba1Gj5K06Z",
        "K-OwXD7iK6rK",
        "FJKl9TDwqXvR",
        "gnoNI54q-U3e",
        "ZHeINj4IUM-5",
        "HXj2UtBQ2xiv",
        "r0YJ9EMtflgB",
        "y5BTi9iyQIcD",
        "XHifneDzWjih",
        "b1ROoIaoFm4A",
        "e6-hdHJVPzlp",
        "cHMzyhlbzEzY",
        "26IL3qkl0UeT",
        "tpHqnK4Kh2PZ",
        "Vi8_kTucKkpH",
        "QUe2mQppiPqC",
        "2XCqVhYOx7V9",
        "t4fP9d6Q3tGO"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error, mean_absolute_error, r2_score\n",
        ")\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "sk0_e8XBrbL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m10e7OogZ40l"
      },
      "outputs": [],
      "source": [
        "def set_random_seeds(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
        "    os.environ['PYTHONHASHSEED'] = \"42\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_random_seeds(42)"
      ],
      "metadata": {
        "id": "-ZfSVPYPwgnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# features excluded from the final feature set based on prior feature selection\n",
        "# + technical columns\n",
        "excluded_features = [ 'x','sq_flag',\n",
        "    'drct_v_lag_6h','drct_v_lag_12h','drct_v_lag_24h','drct_v_lag_48h',\n",
        "    'drct_u_lag_6h','drct_u_lag_24h','drct_u_lag_48h',\n",
        "    'tmpf_lag_12h','tmpf_lag_24h','tmpf_lag_48h',\n",
        "    'hr_flag_rolling_sum_6h','hr_flag_rolling_sum_12h','hr_flag_rolling_sum_24h','hr_flag_rolling_sum_48h',\n",
        "    'sq_flag_rolling_sum_6h','sq_flag_rolling_sum_12h','sq_flag_rolling_sum_24h','sq_flag_rolling_sum_48h',\n",
        "    'relh_grad_rolling_max_6h','relh_grad_rolling_max_12h','relh_grad_rolling_max_24h','relh_grad_rolling_max_48h',\n",
        "    'ts_flag_rolling_sum_6h','ts_flag_rolling_sum_12h','ts_flag_rolling_sum_24h','ts_flag_rolling_sum_48h',\n",
        "    'mslp_rolling_mean_6h','mslp_rolling_mean_12h','mslp_rolling_mean_24h','mslp_rolling_mean_48h',\n",
        "    'gust_rolling_max_12h','gust_rolling_max_24h','gust_rolling_max_48h',\n",
        "    'alti_rolling_mean_6h','alti_rolling_mean_12h','alti_rolling_mean_24h','alti_rolling_mean_48h',\n",
        "    'sknt_rolling_max_6h','sknt_rolling_max_12h','sknt_rolling_max_24h','sknt_rolling_max_48h',\n",
        "    'relh_rolling_mean_6h','relh_rolling_mean_12h','relh_rolling_mean_24h','relh_rolling_mean_48h',\n",
        "    'p0li_rolling_sum_6h','p0li_rolling_sum_12h','p0li_rolling_sum_24h','p0li_rolling_sum_48h',\n",
        "    'time_interval','anomaly_threshold', 'year',\n",
        "    'IDW_ts_flag_rolling_sum_12h','rolling_max_12h','rolling_mean_12h','tmpf_lag_6h','drct_u_lag_12h']\n"
      ],
      "metadata": {
        "id": "pz1u7l0Mtwvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-Step LSTM (Baseline)"
      ],
      "metadata": {
        "id": "ARWAYI7tpQvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# One-Step LSTM 3 Folds time-series validation\n",
        "df_baseline = df.copy()\n",
        "df_baseline[\"log_sum_48\"] = np.log1p(df_baseline[\"sum_48\"])\n",
        "\n",
        "# X and Y\n",
        "X_full = df_baseline.drop(columns=excluded_features, errors=\"ignore\").copy()\n",
        "y_full = df_baseline[\"log_sum_48\"].copy()\n",
        "\n",
        "# numeric columns only\n",
        "X_full = X_full.select_dtypes(include=[\"int64\", \"float64\"])\n",
        "num_cols = X_full.columns\n",
        "\n",
        "# 3 folds time series split\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "def build_model(n_feat: int) -> keras.Model:\n",
        "    m = keras.Sequential([\n",
        "        layers.LSTM(16, dropout=0.2, input_shape=(1, n_feat)),\n",
        "        layers.Dense(1, activation=\"relu\")\n",
        "    ])\n",
        "    m.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "    return m\n",
        "\n",
        "cv_results = []\n",
        "\n",
        "for k, (tr_idx, val_idx) in enumerate(tscv.split(X_full), 1):\n",
        "    print(f\"\\n── Fold {k} \")\n",
        "    X_tr, X_val = X_full.iloc[tr_idx].copy(), X_full.iloc[val_idx].copy()\n",
        "    y_tr, y_val = y_full.iloc[tr_idx].copy(), y_full.iloc[val_idx].copy()\n",
        "\n",
        "    # impute, scale, fit on train only\n",
        "    imp = SimpleImputer(strategy=\"median\").fit(X_tr[num_cols])\n",
        "    scaler = MinMaxScaler().fit(imp.transform(X_tr[num_cols]))\n",
        "\n",
        "    X_tr_prep  = scaler.transform(imp.transform(X_tr[num_cols]))\n",
        "    X_val_prep = scaler.transform(imp.transform(X_val[num_cols]))\n",
        "\n",
        "    # reshape → (samples, 1, n_features)\n",
        "    X_tr_3d  = X_tr_prep.reshape((X_tr_prep.shape[0], 1, len(num_cols)))\n",
        "    X_val_3d = X_val_prep.reshape((X_val_prep.shape[0], 1, len(num_cols)))\n",
        "\n",
        "    model = build_model(len(num_cols))\n",
        "    es = EarlyStopping(monitor=\"loss\", patience=2, restore_best_weights=True)\n",
        "\n",
        "    model.fit(X_tr_3d, y_tr,\n",
        "              epochs=30, batch_size=32,\n",
        "              callbacks=[es], verbose=0)\n",
        "\n",
        "    # predict and metrics\n",
        "    y_val_pred_log = model.predict(X_val_3d, verbose=0).ravel()\n",
        "\n",
        "    # log-scale\n",
        "    mse_log  = mean_squared_error(y_val, y_val_pred_log)\n",
        "    rmse_log = np.sqrt(mse_log)\n",
        "    mae_log  = mean_absolute_error(y_val, y_val_pred_log)\n",
        "    r2_log   = r2_score(y_val, y_val_pred_log)\n",
        "\n",
        "    # original scale\n",
        "    y_true_org = np.expm1(y_val)\n",
        "    y_pred_org = np.expm1(y_val_pred_log)\n",
        "\n",
        "    mse_org  = mean_squared_error(y_true_org, y_pred_org)\n",
        "    rmse_org = np.sqrt(mse_org)\n",
        "    mae_org  = mean_absolute_error(y_true_org, y_pred_org)\n",
        "    r2_org   = r2_score(y_true_org, y_pred_org)\n",
        "\n",
        "    print(f\"Log  : MSE={mse_log:.4f} RMSE={rmse_log:.4f} \"\n",
        "          f\"MAE={mae_log:.4f} R²={r2_log:.4f}\")\n",
        "    print(f\"Orig : MSE={mse_org:,.0f} RMSE={rmse_org:,.0f} \"\n",
        "          f\"MAE={mae_org:,.0f} R²={r2_org:.4f}\")\n",
        "\n",
        "    cv_results.append([k, mse_log, rmse_log, mae_log, r2_log,\n",
        "                          mse_org, rmse_org, mae_org, r2_org])\n",
        "\n",
        "# pivot table\n",
        "cv_df = pd.DataFrame(cv_results, columns=[\n",
        "    \"fold\", \"mse_log\", \"rmse_log\", \"mae_log\", \"r2_log\",\n",
        "    \"mse_org\", \"rmse_org\", \"mae_org\", \"r2_org\"\n",
        "]).set_index(\"fold\")\n",
        "\n",
        "print(\"\\n3-Fold CV summary\")\n",
        "display(cv_df.round(4))\n",
        "\n",
        "print(\"\\nAverages across folds:\")\n",
        "display(cv_df.mean().round(4))"
      ],
      "metadata": {
        "id": "694DwNlTfFu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Step LSTM on full Train (2021)\n",
        "df_baseline = df_train_real.copy()\n",
        "df_baseline['log_sum_48'] = np.log1p(df_baseline['sum_48'])\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1) X / y  (убираем лишние колонки)\n",
        "# --------------------------------------------------\n",
        "X_base = df_baseline.drop(columns=excluded_features, errors='ignore').copy()\n",
        "y_base = df_baseline['log_sum_48'].copy()\n",
        "\n",
        "# keep only numeric columns\n",
        "non_num  = X_base.select_dtypes(exclude=['int64', 'float64']).columns\n",
        "X_base.drop(columns=non_num, inplace=True)\n",
        "\n",
        "num_cols = X_base.columns               # saved features order\n",
        "\n",
        "\n",
        "# inf to NaN; SimpleImputer; Min-Max scaler\n",
        "X_base.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "imp_base = SimpleImputer(strategy='median').fit(X_base[num_cols])\n",
        "X_base[num_cols] = imp_base.transform(X_base[num_cols])\n",
        "\n",
        "scaler_base = MinMaxScaler().fit(X_base[num_cols])\n",
        "X_base_scaled = scaler_base.transform(X_base[num_cols])\n",
        "\n",
        "# reshape and train\n",
        "X_base_3d = X_base_scaled.reshape(\n",
        "    (X_base_scaled.shape[0], 1, len(num_cols))\n",
        ")\n",
        "\n",
        "model_base = keras.Sequential([\n",
        "    layers.LSTM(16, input_shape=(1, len(num_cols))),\n",
        "    layers.Dense(1, activation='relu')\n",
        "])\n",
        "model_base.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='loss',\n",
        "                               patience=2,\n",
        "                               restore_best_weights=True)\n",
        "\n",
        "model_base.fit(\n",
        "    X_base_3d, y_base,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# metrics in log scale\n",
        "y_pred_log = model_base.predict(X_base_3d, verbose=0).ravel()\n",
        "\n",
        "print(\"\\n=== Baseline LSTM — TRAIN (log-scale) ===\")\n",
        "print(f\"MSE : {mean_squared_error(y_base, y_pred_log):.4f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_base, y_pred_log)):.4f}\")\n",
        "print(f\"MAE : {mean_absolute_error(y_base, y_pred_log):.4f}\")\n",
        "print(f\"R²  : {r2_score(y_base, y_pred_log):.4f}\")\n",
        "\n",
        "# metrics in original scale\n",
        "y_true_orig = np.expm1(y_base)\n",
        "y_pred_orig = np.expm1(y_pred_log)\n",
        "\n",
        "print(\"\\n=== Baseline LSTM — TRAIN (original scale) ===\")\n",
        "print(f\"MSE : {mean_squared_error(y_true_orig, y_pred_orig):,.2f}\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_true_orig, y_pred_orig)):,.2f}\")\n",
        "print(f\"MAE : {mean_absolute_error(y_true_orig, y_pred_orig):,.2f}\")\n",
        "print(f\"R²  : {r2_score(y_true_orig, y_pred_orig):.4f}\")"
      ],
      "metadata": {
        "id": "ijzEPUtvFCN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Step LSTM inference on Test (2022)\n",
        "df_baseline_test = df_test_real.copy()\n",
        "df_baseline_test['log_sum_48'] = np.log1p(df_baseline_test['sum_48'])\n",
        "\n",
        "# ←   num_cols_base – список признаков, на которых тренировался baseline\n",
        "X_base_test = (df_baseline_test\n",
        "               .drop(columns=excluded_features, errors='ignore')\n",
        "               .reindex(columns=num_cols))     # fixed order\n",
        "\n",
        "y_base_test = df_baseline_test['log_sum_48'].copy()\n",
        "\n",
        "# imputer, scaler\n",
        "X_base_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_base_test[num_cols] = imp_base.transform(X_base_test[num_cols])\n",
        "X_base_test_scaled = scaler_base.transform(X_base_test[num_cols])\n",
        "\n",
        "# reshape and predict\n",
        "X_base_test_3d = X_base_test_scaled.reshape(\n",
        "        (X_base_test_scaled.shape[0], 1, len(num_cols))\n",
        ")\n",
        "\n",
        "y_test_pred_log_base = model_base.predict(X_base_test_3d).ravel()\n",
        "\n",
        "# metrics in log-scale\n",
        "mse_log_base  = mean_squared_error(y_base_test, y_test_pred_log_base)\n",
        "rmse_log_base = np.sqrt(mse_log_base)\n",
        "mae_log_base  = mean_absolute_error(y_base_test, y_test_pred_log_base)\n",
        "r2_log_base   = r2_score(y_base_test, y_test_pred_log_base)\n",
        "\n",
        "print(\"\\nBaseline LSTM on TEST-2022 (log-scale) \")\n",
        "print(f\"MSE ={mse_log_base :.4f} | RMSE={rmse_log_base:.4f} | \"\n",
        "      f\"MAE ={mae_log_base :.4f} | R² ={r2_log_base :.4f}\")\n",
        "\n",
        "# metrics in original scale\n",
        "y_true_orig = np.expm1(y_base_test)\n",
        "y_pred_orig = np.expm1(y_test_pred_log_base)\n",
        "\n",
        "mse_orig  = mean_squared_error(y_true_orig, y_pred_orig)\n",
        "rmse_orig = np.sqrt(mse_orig)\n",
        "mae_orig  = mean_absolute_error(y_true_orig, y_pred_orig)\n",
        "r2_orig   = r2_score(y_true_orig, y_pred_orig)\n",
        "\n",
        "print(f\"RMSE_orig={rmse_orig:.2f} | MAE_orig={mae_orig:.2f} | \"\n",
        "      f\"R²={r2_orig:.4f} | MSE_orig={mse_orig:.2f}\")\n",
        "print(\"\\n Baseline LSTM on TEST-2022 (original scale) \")\n",
        "print(f\"MSE ={mse_orig:.2f} | RMSE={rmse_orig:.2f} | \"\n",
        "      f\"MAE ={mae_orig:.2f} | R² ={r2_orig:.4f}\")"
      ],
      "metadata": {
        "id": "8bdohE-LpQvY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4JesAkmtOMKC",
        "rsotk1R3Oi4I",
        "R-ba1Gj5K06Z",
        "K-OwXD7iK6rK",
        "FJKl9TDwqXvR",
        "gnoNI54q-U3e",
        "ZHeINj4IUM-5",
        "HXj2UtBQ2xiv",
        "r0YJ9EMtflgB",
        "y5BTi9iyQIcD",
        "XHifneDzWjih",
        "b1ROoIaoFm4A",
        "e6-hdHJVPzlp",
        "cHMzyhlbzEzY",
        "26IL3qkl0UeT",
        "tpHqnK4Kh2PZ",
        "Vi8_kTucKkpH",
        "QUe2mQppiPqC",
        "2XCqVhYOx7V9",
        "t4fP9d6Q3tGO"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}